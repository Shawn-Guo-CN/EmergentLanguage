from abc import ABC, abstractmethod, abstractstaticmethod
from .utils import args

import torch.nn as nn


class BaseGame(ABC):
    def __init__(self, 
        data_loader, 
        optimiser=args.optimiser,
        learning_rate=args.learning_rate,
    ):
        """Initialise the elements of games including (but not limited to):
            i) agents, i.e. speaker and listener;
            ii) reward/loss function and optimiser;
            iii) data loader.

        Args:
            data_loader: instance from package 'data_loader'; class that could enumerate all inputs (in torch.Tensor).
            optimiser: torch.optim instance;
            learning_rate: float; 

        """
        self.data_loader = data_loader
        self.speaker, self.listener = self._init_agents()
        self.speaker_optimiser = optimiser(self.speaker.parameters(), lr=learning_rate)
        self.listener_optimiser = optimiser(self.listener.parameters(), lr=learning_rate)

    def train_epoch(self, data_batch, tau=args.tau, clip=args.clip):

        self.speaker_optimiser.zero_grad()
        self.listener_optimiser.zero_grad()

        loss, print_loss, acc, c_correct, log_msg_prob, log_choose_prob,\
             baseline, spk_entropy = model(data_batch, tau)

        # different backpropogation method for different tricks
        if args.msg_mode == 'REINFORCE':
            (c_correct.detach() * log_msg_prob + 0.05 * spk_entropy).mean().backward()
            (c_correct.detach() * log_choose_prob).mean().backward()
        elif args.msg_mode == 'SCST':
            ((c_correct.detach()-baseline.detach()) * log_msg_prob).mean().backward()
            ((c_correct.detach()-baseline.detach()) * log_choose_prob).mean().backward()
        elif args.msg_mode == 'GUMBEL':
            loss.mean().backward()
        else:
            raise NotImplementedError
        
        nn.utils.clip_grad_norm_(model.parameters(), clip)
        self.speaker_optimiser.step()
        self.listener_optimiser.step()

        return acc, print_loss

        m_optimizer.zero_grad()
        s_optimizer.zero_grad()
        l_optimizer.zero_grad()

        loss, log_msg_prob, log_seq_prob, baseline, print_losses, \
            seq_correct, tok_acc, seq_acc , _, s_entropy = model(data_batch, tau)

        if args.msg_mode == 'REINFORCE':
            log_msg_prob = (-seq_correct.detach() * log_msg_prob).mean()
            log_msg_prob.backward()
            log_seq_prob = (-seq_correct.detach() * log_seq_prob).mean()
            log_seq_prob.backward()
        elif args.msg_mode == 'SCST':
            log_msg_prob = ((loss.detach() - baseline.detach()) * log_msg_prob).mean()
            log_msg_prob.backward()
        elif args.msg_mode == 'GUMBEL':
            loss.mean().backward()
    
        nn.utils.clip_grad_norm_(model.parameters(), clip)
        m_optimizer.step()
        s_optimizer.step()
        l_optimizer.step()

        return seq_acc, tok_acc, sum(print_losses) / len(print_losses)

    @abstractmethod
    def train(self):
        """Train agents in the game.

        Usually, it should contain three steps: i) percept; ii) act; iii) reward/loss backpropagation.

        An example is:
            ```python
            messages, logits, msg_mask = self.percept(x)
            return logits, self.act(messages, msg_masks, candidates)
            ```
        """
        raise NotImplementedError

    def get_language(self, x):
        """Get langauge from agents.

        Extract the emergent language from agents either during or after training.

        Args:
            x: torch.Tensor instance; the objects from environments for speakers to observe.
        
        Returns:
            messages: torch.Tensor instance; the messages generated by speakers.
            logits: torch.Tensor instance; the logits for generating messages, the size should be B*T*V where: i) B is 
                batch size; ii) T is the maximum length of messages; iii) V is the vocabulary size.
        """

        messages, logits, _ = self.percept(x)
        return messages, logits

    @abstractmethod
    def percept(self, x):
        """Perception procedure of speakers.

        Procedure for speakers to: i) observe the input object, ii) generate messages for listeners.

        Args:
            x: torch.Tensor instance; the objects from environments for speakers to observe.
            
        Returns:
            messages: torch.Tensor instance; the messages generated by speakers.
            logits: torch.Tensor instance; the logits for generating messages, the size should be B*T*V where: i) B is 
                batch size; ii) T is the maximum length of messages; iii) V is the vocabulary size.
            masks: torch.Tensor instance; the mask matrix for messages to make using 
                torch.nn.utils.rnn.pack_padded_sequence easier.
        """
        raise NotImplementedError

    @abstractmethod
    def act(self):
        """Act procedure of listeners.

        Procedure for listeners to: i) encode the input object, ii) perform the required actions (reference or 
        reconstructions).

        Returns:
            Implemented by different kinds of games.
        """
        raise NotImplementedError

    @abstractstaticmethod
    def _init_agents():
        raise NotImplementedError